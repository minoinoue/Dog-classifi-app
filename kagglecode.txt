import os
import shutil
import random
from tqdm import tqdm
import cv2
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import datasets, models
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import matplotlib.pyplot as plt

# ======= HÃ m chia dataset =======
def split_dataset(images_dir, output_dir='dataset', train_ratio=0.8, seed=42):
    random.seed(seed)
    train_dir = os.path.join(output_dir, 'train')
    test_dir = os.path.join(output_dir, 'test')
    if os.path.exists(output_dir):
        print(f"ThÆ° má»¥c '{output_dir}' Ä‘Ã£ tá»“n táº¡i. Bá» qua bÆ°á»›c chia dataset.")
        return
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)
    class_dirs = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]
    for class_folder in tqdm(class_dirs, desc="ğŸ“ Äang xá»­ lÃ½ cÃ¡c lá»›p"):
        full_class_path = os.path.join(images_dir, class_folder)
        class_name = class_folder.split('-')[1]
        images = [f for f in os.listdir(full_class_path) if f.lower().endswith('.jpg')]
        random.shuffle(images)
        split_idx = int(len(images) * train_ratio)
        train_images = images[:split_idx]
        test_images = images[split_idx:]
        for img_name in train_images:
            src_path = os.path.join(full_class_path, img_name)
            dst_folder = os.path.join(train_dir, class_name)
            os.makedirs(dst_folder, exist_ok=True)
            shutil.copy(src_path, os.path.join(dst_folder, img_name))
        for img_name in test_images:
            src_path = os.path.join(full_class_path, img_name)
            dst_folder = os.path.join(test_dir, class_name)
            os.makedirs(dst_folder, exist_ok=True)
            shutil.copy(src_path, os.path.join(dst_folder, img_name))
    print("âœ… HoÃ n táº¥t! Dataset Ä‘Ã£ chia theo tá»· lá»‡ 80/20.")

# ======= Config =======
IMAGES_DIR = "/kaggle/input/stanford-dogs-dataset/images/Images"
OUTPUT_DIR = "/kaggle/working/dataset"
split_dataset(IMAGES_DIR, OUTPUT_DIR)
data_dir = OUTPUT_DIR
train_dir = os.path.join(data_dir, "train")

PHASE1_EPOCHS = 8
PHASE2_EPOCHS = 22
NUM_TOTAL_EPOCHS = PHASE1_EPOCHS + PHASE2_EPOCHS
batch_size = 32
patience = 5
best_val_loss = float('inf')
epochs_no_improve = 0
early_stop = False
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# <<< "On-the-Fly" Augmentation >>>

# Äá»‹nh nghÄ©a lá»›p tÃ¹y chá»‰nh Ä‘á»ƒ thÃªm nhiá»…u Gaussian vÃ o Tensor
class AddGaussianNoise(object):
    def __init__(self, mean=0., std=25.):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        # ThÃªm nhiá»…u vÃ o tensor, chia cho 255.0 Ä‘á»ƒ chuáº©n hÃ³a Ä‘á»™ lá»‡ch chuáº©n
        return tensor + torch.randn(tensor.size()) * self.std / 255.0 + self.mean / 255.0

    def __repr__(self):
        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std})'

# Pipeline tÄƒng cÆ°á»ng dá»¯ liá»‡u
train_transforms = transforms.Compose([
    transforms.RandomRotation(degrees=15),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.2)),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),

    # Chuyá»ƒn áº£nh sang Tensor
    transforms.ToTensor(),

    # Ãp dá»¥ng cÃ¡c phÃ©p biáº¿n Ä‘á»•i tÃ¹y chá»‰nh trÃªn Tensor má»™t cÃ¡ch ngáº«u nhiÃªn
    transforms.RandomApply([
        transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0))
    ], p=0.3), # 30% sá»‘ áº£nh sáº½ bá»‹ lÃ m má»

    transforms.RandomApply([
        AddGaussianNoise(0., 25.)
    ], p=0.3), # 30% sá»‘ áº£nh sáº½ bá»‹ thÃªm nhiá»…u

    # Chuáº©n hÃ³a (luÃ´n lÃ  bÆ°á»›c cuá»‘i cÃ¹ng)
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Transform cho táº­p test/validation khÃ´ng cáº§n tÄƒng cÆ°á»ng dá»¯ liá»‡u
test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# DataLoaders
full_train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)
test_dataset = datasets.ImageFolder(os.path.join(data_dir, "test"), transform=test_transforms)
val_ratio = 0.2
val_size = int(len(full_train_dataset) * val_ratio)
train_size = len(full_train_dataset) - val_size
train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])

# GÃ¡n transform riÃªng cho validation set Ä‘á»ƒ khÃ´ng bá»‹ augmentation
val_dataset.dataset.transform = test_transforms

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
num_classes = len(full_train_dataset.classes)
print(f"ğŸ”¢ Sá»‘ class: {num_classes} | Classes: {full_train_dataset.classes}")

# ======= MODEL =======
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
num_ftrs = model.fc.in_features

model.fc = nn.Sequential(
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.Dropout(0.5),

    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.3),

    nn.Linear(256, num_classes)
)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
history = {
    'epoch': [], 'train_loss': [], 'train_acc': [], 'train_precision': [], 'train_recall': [], 'train_f1': [],
    'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1': [],
}

# HÃ m training/validation cho má»™t epoch
def run_epoch(epoch, current_phase):
    global best_val_loss, epochs_no_improve, early_stop
    model.train()
    train_loss, train_labels, train_preds = 0.0, [], []
    train_desc = f"Giai Ä‘oáº¡n {current_phase} - Training"
    for inputs, labels in tqdm(train_loader, desc=train_desc):
        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        train_labels.extend(labels.cpu().numpy())
        train_preds.extend(preds.cpu().numpy())

    avg_train_loss = train_loss / len(train_loader)
    train_acc = accuracy_score(train_labels, train_preds)
    train_precision = precision_score(train_labels, train_preds, average='weighted', zero_division=0)
    train_recall = recall_score(train_labels, train_preds, average='weighted', zero_division=0)
    train_f1 = f1_score(train_labels, train_preds, average='weighted', zero_division=0)
    print(f"âœ… Train Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1: {train_f1:.4f}")

    model.eval()
    val_loss, val_labels, val_preds = 0.0, [], []
    val_desc = f"Giai Ä‘oáº¡n {current_phase} - Validation"
    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc=val_desc):
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            val_labels.extend(labels.cpu().numpy())
            val_preds.extend(preds.cpu().numpy())

    avg_val_loss = val_loss / len(val_loader)
    val_acc = accuracy_score(val_labels, val_preds)
    val_precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)
    val_recall = recall_score(val_labels, val_preds, average='weighted', zero_division=0)
    val_f1 = f1_score(val_labels, val_preds, average='weighted', zero_division=0)
    print(f"ğŸ“Š Val Loss:   {avg_val_loss:.4f} | Acc: {val_acc:.4f} | Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}")

    history['epoch'].append(epoch)
    history['train_loss'].append(avg_train_loss); history['train_acc'].append(train_acc); history['train_precision'].append(train_precision); history['train_recall'].append(train_recall); history['train_f1'].append(train_f1)
    history['val_loss'].append(avg_val_loss); history['val_acc'].append(val_acc); history['val_precision'].append(val_precision); history['val_recall'].append(val_recall); history['val_f1'].append(val_f1)

    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), "best_resnet50_dogs.pth")
        print("âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t!")
    else:
        epochs_no_improve += 1
        if epochs_no_improve >= patience:
            print("â¹ï¸ Early stopping triggered.")
            early_stop = True
    if scheduler:
        scheduler.step(avg_val_loss)

# =============== Báº®T Äáº¦U TRAINING ===============
print(f"ğŸš€ Training trÃªn device: {device}")
# GIAI ÄOáº N 1
print("\n" + "="*50 + f"\n Báº®T Äáº¦U GIAI ÄOáº N 1: HUáº¤N LUYá»†N Lá»šP FC ({PHASE1_EPOCHS} epochs)\n" + "="*50)
for param in model.parameters():
    param.requires_grad = False
for param in model.fc.parameters():
    param.requires_grad = True
optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)
scheduler = None
for epoch in range(PHASE1_EPOCHS):
    if early_stop: break
    print(f"\nğŸ“š Epoch {epoch+1}/{NUM_TOTAL_EPOCHS}")
    run_epoch(epoch + 1, current_phase=1)

# GIAI ÄOáº N 2
print("\n" + "="*50 + f"\n Báº®T Äáº¦U GIAI ÄOáº N 2: FINE-TUNING ({PHASE2_EPOCHS} epochs)\n" + "="*50)
for param in model.layer3.parameters():
    param.requires_grad = True
for param in model.layer4.parameters():
    param.requires_grad = True
params_to_update = [
    {'params': model.layer3.parameters(), 'lr': 1e-6},
    {'params': model.layer4.parameters(), 'lr': 1e-5},
    {'params': model.fc.parameters(), 'lr': 1e-4},
]
optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)
for epoch in range(PHASE1_EPOCHS, NUM_TOTAL_EPOCHS):
    if early_stop: break
    print(f"\nğŸ“š Epoch {epoch+1}/{NUM_TOTAL_EPOCHS}")
    run_epoch(epoch + 1, current_phase=2)

print("\nğŸ‰ğŸ‰ğŸ‰ TRAINING HOÃ€N Táº¤T! ğŸ‰ğŸ‰ğŸ‰")

# =============== LÆ¯U CHá»ˆ Sá» VÃ€ Váº¼ BIá»‚U Äá»’ ===============
df = pd.DataFrame(history)
df.to_csv("training_metrics_finetuned.csv", index=False)
print("ğŸ“ ÄÃ£ lÆ°u cÃ¡c chá»‰ sá»‘ vÃ o 'training_metrics_finetuned.csv'")

plt.figure(figsize=(15, 10))
plt.subplot(2, 2, 1); plt.plot(df['epoch'], df['train_loss'], label='Train Loss'); plt.plot(df['epoch'], df['val_loss'], label='Val Loss'); plt.title('Loss'); plt.legend(); plt.grid(True)
plt.subplot(2, 2, 2); plt.plot(df['epoch'], df['train_f1'], label='Train F1'); plt.plot(df['epoch'], df['val_f1'], label='Val F1'); plt.title('F1 Score'); plt.legend(); plt.grid(True)
plt.subplot(2, 2, 3); plt.plot(df['epoch'], df['train_precision'], label='Train Precision'); plt.plot(df['epoch'], df['val_precision'], label='Val Precision'); plt.title('Precision'); plt.legend(); plt.grid(True)
plt.subplot(2, 2, 4); plt.plot(df['epoch'], df['train_recall'], label='Train Recall'); plt.plot(df['epoch'], df['val_recall'], label='Val Recall'); plt.title('Recall'); plt.legend(); plt.grid(True)
plt.tight_layout(); plt.savefig("metrics_plot_finetuned.png")
print("ğŸ“Š ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ so sÃ¡nh chá»‰ sá»‘ vÃ o 'metrics_plot_finetuned.png'")
plt.show()

plt.figure(figsize=(8, 5))
plt.plot(df['epoch'], df['train_acc'], label='Train Accuracy')
plt.plot(df['epoch'], df['val_acc'], label='Val Accuracy')
plt.axvline(x=PHASE1_EPOCHS, color='r', linestyle='--', label='Báº¯t Ä‘áº§u Giai Ä‘oáº¡n 2')
plt.title('Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True)
plt.tight_layout(); plt.savefig("accuracy_plot_finetuned.png")
print("âœ… ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ Accuracy vÃ o 'accuracy_plot_finetuned.png'")
plt.show()


# =============== ÄÃNH GIÃ TRÃŠN Táº¬P TEST ===============
def evaluate(loader, mode="Test"):
    # Táº£i láº¡i model tá»‘t nháº¥t Ä‘Ã£ lÆ°u
    model.load_state_dict(torch.load("best_resnet50_dogs.pth"))
    model.eval()
    all_labels, all_preds = [], []
    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc=f"[{mode}]"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
    acc = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
    print(f"ğŸ“Š {mode} Accuracy:  {acc:.4f}")
    print(f"ğŸ“Š {mode} Precision: {precision:.4f}")
    print(f"ğŸ“Š {mode} Recall:    {recall:.4f}")
    print(f"ğŸ“Š {mode} F1 Score:  {f1:.4f}")

print("\nğŸ“Œ ÄÃ¡nh giÃ¡ trÃªn táº­p test (sá»­ dá»¥ng model tá»‘t nháº¥t Ä‘Ã£ lÆ°u):")
evaluate(test_loader, mode="Test")