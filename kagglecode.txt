import os
import shutil
import random
from tqdm import tqdm
import cv2
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import datasets, models
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import matplotlib.pyplot as plt

# ======= H√†m chia dataset =======
def split_dataset(images_dir, output_dir='dataset', train_ratio=0.8, seed=42):
    random.seed(seed)
    train_dir = os.path.join(output_dir, 'train')
    test_dir = os.path.join(output_dir, 'test')
    if os.path.exists(output_dir):
        print(f"Th∆∞ m·ª•c '{output_dir}' ƒë√£ t·ªìn t·∫°i. B·ªè qua b∆∞·ªõc chia dataset.")
        return
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)
    class_dirs = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]
    for class_folder in tqdm(class_dirs, desc="üìÅ ƒêang x·ª≠ l√Ω c√°c l·ªõp"):
        full_class_path = os.path.join(images_dir, class_folder)
        class_name = class_folder.split('-')[1]
        images = [f for f in os.listdir(full_class_path) if f.lower().endswith('.jpg')]
        random.shuffle(images)
        split_idx = int(len(images) * train_ratio)
        train_images = images[:split_idx]
        test_images = images[split_idx:]
        for img_name in train_images:
            src_path = os.path.join(full_class_path, img_name)
            dst_folder = os.path.join(train_dir, class_name)
            os.makedirs(dst_folder, exist_ok=True)
            shutil.copy(src_path, os.path.join(dst_folder, img_name))
        for img_name in test_images:
            src_path = os.path.join(full_class_path, img_name)
            dst_folder = os.path.join(test_dir, class_name)
            os.makedirs(dst_folder, exist_ok=True)
            shutil.copy(src_path, os.path.join(dst_folder, img_name))
    print("‚úÖ Ho√†n t·∫•t! Dataset ƒë√£ chia theo t·ª∑ l·ªá 80/20.")

# ======= Config =======
IMAGES_DIR = "/kaggle/input/stanford-dogs-dataset/images/Images"
OUTPUT_DIR = "/kaggle/working/dataset"
split_dataset(IMAGES_DIR, OUTPUT_DIR)
data_dir = OUTPUT_DIR
train_dir = os.path.join(data_dir, "train")

PHASE1_EPOCHS = 8
PHASE2_EPOCHS = 22
NUM_TOTAL_EPOCHS = PHASE1_EPOCHS + PHASE2_EPOCHS
batch_size = 32
patience = 5
best_val_loss = float('inf')
epochs_no_improve = 0
early_stop = False
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# <<< "On-the-Fly" Augmentation >>>

# ƒê·ªãnh nghƒ©a l·ªõp t√πy ch·ªânh ƒë·ªÉ th√™m nhi·ªÖu Gaussian v√†o Tensor
class AddGaussianNoise(object):
    def __init__(self, mean=0., std=25.):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        # Th√™m nhi·ªÖu v√†o tensor, chia cho 255.0 ƒë·ªÉ chu·∫©n h√≥a ƒë·ªô l·ªách chu·∫©n
        return tensor + torch.randn(tensor.size()) * self.std / 255.0 + self.mean / 255.0

    def __repr__(self):
        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std})'

# Pipeline tƒÉng c∆∞·ªùng d·ªØ li·ªáu
train_transforms = transforms.Compose([
    transforms.RandomRotation(degrees=15),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.2)),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),

    # Chuy·ªÉn ·∫£nh sang Tensor
    transforms.ToTensor(),

    # √Åp d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi t√πy ch·ªânh tr√™n Tensor m·ªôt c√°ch ng·∫´u nhi√™n
    transforms.RandomApply([
        transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0))
    ], p=0.3), # 30% s·ªë ·∫£nh s·∫Ω b·ªã l√†m m·ªù

    transforms.RandomApply([
        AddGaussianNoise(0., 25.)
    ], p=0.3), # 30% s·ªë ·∫£nh s·∫Ω b·ªã th√™m nhi·ªÖu

    # Chu·∫©n h√≥a (lu√¥n l√† b∆∞·ªõc cu·ªëi c√πng)
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Transform cho t·∫≠p test/validation kh√¥ng c·∫ßn tƒÉng c∆∞·ªùng d·ªØ li·ªáu
test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# DataLoaders
full_train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)
test_dataset = datasets.ImageFolder(os.path.join(data_dir, "test"), transform=test_transforms)
val_ratio = 0.2
val_size = int(len(full_train_dataset) * val_ratio)
train_size = len(full_train_dataset) - val_size
train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])

# G√°n transform ri√™ng cho validation set ƒë·ªÉ kh√¥ng b·ªã augmentation
val_dataset.dataset.transform = test_transforms

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
num_classes = len(full_train_dataset.classes)
print(f"üî¢ S·ªë class: {num_classes} | Classes: {full_train_dataset.classes}")

# ======= MODEL =======
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
num_ftrs = model.fc.in_features

model.fc = nn.Sequential(
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.Dropout(0.5),

    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.3),

    nn.Linear(256, num_classes)
)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
history = {
    'epoch': [], 'train_loss': [], 'train_acc': [], 'train_precision': [], 'train_recall': [], 'train_f1': [],
    'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1': [],
}

# H√†m training/validation cho m·ªôt epoch
def run_epoch(epoch, current_phase):
    global best_val_loss, epochs_no_improve, early_stop
    model.train()
    train_loss, train_labels, train_preds = 0.0, [], []
    train_desc = f"Giai ƒëo·∫°n {current_phase} - Training"
    for inputs, labels in tqdm(train_loader, desc=train_desc):
        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        train_labels.extend(labels.cpu().numpy())
        train_preds.extend(preds.cpu().numpy())

    avg_train_loss = train_loss / len(train_loader)
    train_acc = accuracy_score(train_labels, train_preds)
    train_precision = precision_score(train_labels, train_preds, average='weighted', zero_division=0)
    train_recall = recall_score(train_labels, train_preds, average='weighted', zero_division=0)
    train_f1 = f1_score(train_labels, train_preds, average='weighted', zero_division=0)
    print(f"‚úÖ Train Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1: {train_f1:.4f}")

    model.eval()
    val_loss, val_labels, val_preds = 0.0, [], []
    val_desc = f"Giai ƒëo·∫°n {current_phase} - Validation"
    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc=val_desc):
            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            val_labels.extend(labels.cpu().numpy())
            val_preds.extend(preds.cpu().numpy())

    avg_val_loss = val_loss / len(val_loader)
    val_acc = accuracy_score(val_labels, val_preds)
    val_precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)
    val_recall = recall_score(val_labels, val_preds, average='weighted', zero_division=0)
    val_f1 = f1_score(val_labels, val_preds, average='weighted', zero_division=0)
    print(f"üìä Val Loss:   {avg_val_loss:.4f} | Acc: {val_acc:.4f} | Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}")

    history['epoch'].append(epoch)
    history['train_loss'].append(avg_train_loss); history['train_acc'].append(train_acc); history['train_precision'].append(train_precision); history['train_recall'].append(train_recall); history['train_f1'].append(train_f1)
    history['val_loss'].append(avg_val_loss); history['val_acc'].append(val_acc); history['val_precision'].append(val_precision); history['val_recall'].append(val_recall); history['val_f1'].append(val_f1)

    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), "best_resnet50_dogs.pth")
        print("‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh t·ªët nh·∫•t!")
    else:
        epochs_no_improve += 1
        if epochs_no_improve >= patience:
            print("‚èπÔ∏è Early stopping triggered.")
            early_stop = True
    if scheduler:
        scheduler.step(avg_val_loss)

# =============== B·∫ÆT ƒê·∫¶U TRAINING ===============
print(f"üöÄ Training tr√™n device: {device}")
# GIAI ƒêO·∫†N 1
print("\n" + "="*50 + f"\n B·∫ÆT ƒê·∫¶U GIAI ƒêO·∫†N 1: HU·∫§N LUY·ªÜN L·ªöP FC ({PHASE1_EPOCHS} epochs)\n" + "="*50)
for param in model.parameters():
    param.requires_grad = False
for param in model.fc.parameters():
    param.requires_grad = True
optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)
scheduler = None
for epoch in range(PHASE1_EPOCHS):
    if early_stop: break
    print(f"\nüìö Epoch {epoch+1}/{NUM_TOTAL_EPOCHS}")
    run_epoch(epoch + 1, current_phase=1)

# GIAI ƒêO·∫†N 2
print("\n" + "="*50 + f"\n B·∫ÆT ƒê·∫¶U GIAI ƒêO·∫†N 2: FINE-TUNING ({PHASE2_EPOCHS} epochs)\n" + "="*50)
for param in model.layer3.parameters():
    param.requires_grad = True
for param in model.layer4.parameters():
    param.requires_grad = True
params_to_update = [
    {'params': model.layer3.parameters(), 'lr': 1e-6},
    {'params': model.layer4.parameters(), 'lr': 1e-5},
    {'params': model.fc.parameters(), 'lr': 1e-4},
]
optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)
for epoch in range(PHASE1_EPOCHS, NUM_TOTAL_EPOCHS):
    if early_stop: break
    print(f"\nüìö Epoch {epoch+1}/{NUM_TOTAL_EPOCHS}")
    run_epoch(epoch + 1, current_phase=2)

print("\nüéâüéâüéâ TRAINING HO√ÄN T·∫§T! üéâüéâüéâ")

# =============== L∆ØU CH·ªà S·ªê V√Ä V·∫º BI·ªÇU ƒê·ªí ===============
df = pd.DataFrame(history)
df.to_csv("training_metrics_finetuned.csv", index=False)
print("üìÅ ƒê√£ l∆∞u c√°c ch·ªâ s·ªë v√†o 'training_metrics_finetuned.csv'")

plt.figure(figsize=(15, 10))
plt.subplot(2, 2, 1); plt.plot(df['epoch'], df['train_loss'], label='Train Loss'); plt.plot(df['epoch'], df['val_loss'], label='Val Loss'); plt.title('Loss'); plt.legend(); plt.grid(True)
plt.subplot(2, 2, 2); plt.plot(df['epoch'], df['train_f1'], label='Train F1'); plt.plot(df['epoch'], df['val_f1'], label='Val F1'); plt.title('F1 Score'); plt.legend(); plt.grid(True)
plt.subplot(2, 2, 3); plt.plot(df['epoch'], df['train_precision'], label='Train Precision'); plt.plot(df['epoch'], df['val_precision'], label='Val Precision'); plt.title('Precision'); plt.legend(); plt.grid(True)
plt.subplot(2, 2, 4); plt.plot(df['epoch'], df['train_recall'], label='Train Recall'); plt.plot(df['epoch'], df['val_recall'], label='Val Recall'); plt.title('Recall'); plt.legend(); plt.grid(True)
plt.tight_layout(); plt.savefig("metrics_plot_finetuned.png")
print("üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì so s√°nh ch·ªâ s·ªë v√†o 'metrics_plot_finetuned.png'")
plt.show()

plt.figure(figsize=(8, 5))
plt.plot(df['epoch'], df['train_acc'], label='Train Accuracy')
plt.plot(df['epoch'], df['val_acc'], label='Val Accuracy')
plt.axvline(x=PHASE1_EPOCHS, color='r', linestyle='--', label='B·∫Øt ƒë·∫ßu Giai ƒëo·∫°n 2')
plt.title('Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True)
plt.tight_layout(); plt.savefig("accuracy_plot_finetuned.png")
print("‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì Accuracy v√†o 'accuracy_plot_finetuned.png'")
plt.show()


# =============== ƒê√ÅNH GI√Å TR√äN T·∫¨P TEST ===============
def evaluate(loader, mode="Test"):
    # T·∫£i l·∫°i model t·ªët nh·∫•t ƒë√£ l∆∞u
    model.load_state_dict(torch.load("best_resnet50_dogs.pth"))
    model.eval()
    all_labels, all_preds = [], []
    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc=f"[{mode}]"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
    acc = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
    print(f"üìä {mode} Accuracy:  {acc:.4f}")
    print(f"üìä {mode} Precision: {precision:.4f}")
    print(f"üìä {mode} Recall:    {recall:.4f}")
    print(f"üìä {mode} F1 Score:  {f1:.4f}")

print("\nüìå ƒê√°nh gi√° tr√™n t·∫≠p test (s·ª≠ d·ª•ng model t·ªët nh·∫•t ƒë√£ l∆∞u):")
evaluate(test_loader, mode="Test")